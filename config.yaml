# Basic Settings
output:
  directory: "data"
  filename: "insider_trades.csv"
  format: "csv"  # Possible values: csv, parquet

# Scraping Settings
scraping:
  start_year: 2015  # From which year should data be retrieved
  start_month: 1    # From which month in start_year
  max_workers: 10   # Number of parallel downloads
  retry_attempts: 3 # Number of retry attempts on errors
  timeout: 30       # Timeout in seconds for HTTP requests

# Filter Settings
filters:
  min_transaction_value: 50     # Minimum transaction value in 1000 dollar increments (100 == 100,000)
  transaction_types: ["P - Purchase" ,"S - Sale"]        # Empty = all types, or list: ["P - Purchase" ,"S - Sale", "S - Sale+OE"]
  exclude_companies: []        # List of ticker symbols to exclude
  include_companies: []        # List of ticker symbols to include
  min_shares_traded: 0        # Minimum number of traded shares

# Logging Settings
logging:
  level: "INFO"               # DEBUG, INFO, WARNING, ERROR
  file: "openinsider.log"
  rotate_logs: true          # Archive old logs
  max_log_size: 10           # Maximum log size in MB

# Cache Settings
cache:
  enabled: true              # Enable/disable cache
  directory: ".cache"        # Cache directory
  max_age: 24               # Maximum age of cache files in hours
